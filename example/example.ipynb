{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f7ec8a-44d3-4e37-8991-945b8407cb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# enable .py change and reflect its change on this notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bb9d90a-72ef-4bac-a4e9-5b5fabc319fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex \n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# you need to copy 'preprocessing.py' & 'detector.py' to the same directory of this notebook.\n",
    "from preprocessing import Preprocessing\n",
    "from detector import Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea156ab7-6e7a-48f9-a9b9-15a9cb3dc8a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Read data & set necessary data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64611e6a-0cd1-4a4e-bc9d-36bde174f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ PATH ============ \n",
    "# Path should be absolute path.\n",
    "PATH_ROW_ACKNOW = os.environ.get('DATA_ROWACK')\n",
    "PATH_MAG = os.environ.get('DATA_MAG')\n",
    "FILES = ['compbiology', 'biology', 'medicine', 'genetics', 'ntds', 'pathogenes', 'plosone', 'srep']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c31509f3-a46e-4ac5-87b8-1504009a20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============ DB (MAG) ============\n",
    "\"\"\"To check the necessary data structure of DB data, \n",
    "example csv data of DB are in the same directory 'exampleDB(mag)'. \n",
    "\n",
    ".exampleDB(mag)\n",
    "├── example_db_author.csv\n",
    "├── example_db_paper_author.csv\n",
    "├── example_db_paper_refPaper.csv\n",
    "└── example_df_doi_paperId.csv\n",
    "\"\"\"\n",
    "# DB data (it should be csv or .hdf5 file)\n",
    "FILE_DB_AUTHOR = f'{PATH_MAG}/Authors/Authors.csv' # please set your path\n",
    "FILE_DB_PAPER_AUTHOR = f'{PATH_MAG}/PaperAuthorAffiliations/PaperAuthorAffiliations.csv' # please set your path\n",
    "FILE_DB_PAPER_REFPAPER = f'{PATH_MAG}/PaperReferences/PaperReferences.csv.hdf5' # please set your path\n",
    "# doi to paperID\n",
    "df_magpaper_id_doi_plos = pd.read_table(f'{PATH_MAG}/papers_plos.txt', sep=' ', names=['PaperId', 'Doi']) # please set your path\n",
    "df_magpaper_id_doi_srep = pd.read_table(f'{PATH_MAG}/papers_srep.txt', sep=' ', names=['PaperId', 'Doi']) # please set your path\n",
    "df_doi_paperId = pd.concat([df_magpaper_id_doi_plos, df_magpaper_id_doi_srep])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d42d36d-5d7d-4b80-95c5-6875334c97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read file: compbiology\n",
      "read file: biology\n",
      "read file: medicine\n",
      "read file: genetics\n",
      "read file: ntds\n",
      "read file: pathogenes\n",
      "read file: plosone\n",
      "read file: srep\n"
     ]
    }
   ],
   "source": [
    "# ============ Acknowledgment data ============\n",
    "\"\"\"To check the necessary data structure of acknowledgement data, \n",
    "example csv data of input df_acknow is in the same directory of 'exampleAcknow'. \n",
    "\n",
    ".exampleAcknow\n",
    "└── example_df_acknow.csv\n",
    "\"\"\"\n",
    "\n",
    "# Acknow data (Please read your data. The following script to read acknow data is just my case.)\n",
    "# You may just need to run ``` acknowdata_used pd.read_csv('your_path') ```\n",
    "def _split_dataframe(df, chunk_size = 10000): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# Read acknow data & concat all dfs\n",
    "dfs = {}\n",
    "dfs_all = pd.DataFrame()\n",
    "for file in FILES:\n",
    "    print(f\"read file: {file}\")\n",
    "    dfs[file] = pd.read_csv(f'{PATH_ROW_ACKNOW}/{file}.csv', low_memory=False)[['paperId', 'author', 'acknow']]\n",
    "    dfs_all = pd.concat([dfs_all, dfs[file]])\n",
    "# rename columns\n",
    "dfs_all_renamed = dfs_all.rename({'paperId': 'Doi', 'acknow':'AcknowName'}, axis=1)\n",
    "\n",
    "# data to use\n",
    "df_split = _split_dataframe(dfs_all_renamed) # split into small\n",
    "acknowdata_used = df_split[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b3596-4983-4477-af90-88cadc43a403",
   "metadata": {},
   "source": [
    "In the following, large data might takes time, so split into small dataset and we will use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b42d1e-3330-4a59-ad1e-c9fb86309093",
   "metadata": {},
   "source": [
    "# Whole Process once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8e6b958-2d32-4f75-b17c-95255104c283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_preprocess(pre):\n",
    "    print('\\n Start Preprocessing ...')\n",
    "    df_acknow = pre.adjust_df_acknow()\n",
    "    v_db_author, v_db_paper_author, v_db_paper_refPaper = pre.read_db_as_vaex()\n",
    "\n",
    "    # check\n",
    "    if df_acknow.empty: \n",
    "        print('=== Acknow data(Doi or/and AcknowName) does not exist in DB data ===')\n",
    "        return pd.DataFrame.from_dict({'PaperId': [], 'AcknowName':[]}), v_db_author, v_db_paper_author, v_db_paper_refPaper\n",
    "    \n",
    "    return df_acknow, v_db_author, v_db_paper_author, v_db_paper_refPaper\n",
    "    \n",
    "def run_detecor(detector, df_doi_paperId, stats=False):\n",
    "    print('\\n Start Detector')\n",
    "    # get possible acknow Ids and dataframe\n",
    "    df_acknow_possibleIds_grouped, possible_acknow_ids = detector.possible_acknoweldged_candidates_id()\n",
    "\n",
    "    # check2\n",
    "    if len(possible_acknow_ids) == 0:\n",
    "        print('Possible scholar ID containing ANY AcknowName in the input data could not be found in DB')\n",
    "        return\n",
    "\n",
    "    # Collaboration approach\n",
    "    df_acknow_with_collab_identified = detector.collaboration_approach(possible_acknow_ids, df_acknow_possibleIds_grouped)\n",
    "\n",
    "    # Citation approach\n",
    "    df_authorIds_citedAuthorIds_identified = detector.citation_approach(df_acknow_possibleIds_grouped)\n",
    "\n",
    "    # Combine both approaches\n",
    "    df_acknowId = detector.merge_two_approach(df_acknow_with_collab_identified, df_authorIds_citedAuthorIds_identified)\n",
    "\n",
    "    # Formatting\n",
    "    df_acknowId = detector.format_result(df_acknowId, df_doi_paperId)\n",
    "\n",
    "    # save\n",
    "    if detector.save_file != '':\n",
    "        df_acknowId.to_csv(detector.save_file, index=False)\n",
    "    \n",
    "    # stats\n",
    "    if stats:\n",
    "        print(detector.stats(detector.df_acknow, df_acknowId))\n",
    "        \n",
    "    return df_acknowId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3c989ea-eaf5-4b07-a74b-98b3701c2120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!! DB data(/Users/keigokusumegi/research/data/MAG/Authors/Authors.csv.hdf5) exits as vaex.\n",
      "OK!! DB data(/Users/keigokusumegi/research/data/MAG/PaperAuthorAffiliations/PaperAuthorAffiliations.csv.hdf5) exits as vaex.\n",
      "OK!! DB data(/Users/keigokusumegi/research/data/MAG/PaperReferences/PaperReferences.csv.hdf5) exits as vaex.\n",
      "\n",
      " Start Preprocessing ...\n"
     ]
    }
   ],
   "source": [
    "# ============ PREPROCESSING ============\n",
    "# preprocessing the acknow and DB data \n",
    "pre = Preprocessing(acknowdata_used, df_doi_paperId, FILE_DB_AUTHOR, FILE_DB_PAPER_AUTHOR, FILE_DB_PAPER_REFPAPER)\n",
    "df_acknow, v_db_author, v_db_paper_author, v_db_paper_refPaper = run_preprocess(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aefcfe7-efa2-42f6-be4b-7059ae96f7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Start Detector\n",
      "Start possible scholar Id search\n",
      "End possible_acknoweldged_candidates_id (Time in this part: 9.94s)\n",
      "Start collaboration_approach\n",
      "    - sub step1 : _find_target_authorIds. (Time: 7.82s)\n",
      "    - sub step2: _published_paperIds_of_target_authors. (Time: 18.67s)\n",
      "      -- get all collaborators of target_authors\n",
      "      -- confine collaborators by using possible acknowledged scholars Ids(=acknow_candidate_ids) \n",
      "    - sub step3: _collaborators_of_paperId. (Time: 34.14s)\n",
      "    - sub step4: _merge_to_create_author_collabIds. (Time: 34.20s)\n",
      "  - Done: Step1.\n",
      "  - Done: Step2. (Time: 34.25s)\n",
      "  - Done: Step3. (Time: 34.61s)\n",
      "Start citation_approach\n",
      "  - Done: Step1. (Time: 28.50s)\n",
      "  - Done: Step2. (Time: 28.51s)\n",
      "Merging collab. and citation approach results ...\n",
      "Format the resutls\n",
      "{'Num of input scholars names': 2316, 'Num of input papers': 659, 'Num of identified acknowledged scholars': 855, 'Num of papers with identified acknowledged scholars': 431, 'Proportion of identified scholars per input names': '0.3692', 'Num identified scholars by Collab. approach': 431, 'Num identified scholars by Reference approach': 147, 'Num identified scholars by Both approach': 329, 'Overall computational time': 1}\n"
     ]
    }
   ],
   "source": [
    "# ============ DETECTOR ============\n",
    "# Initialize with the necessary data\n",
    "detector = Detector(df_acknow, v_db_author, v_db_paper_author, v_db_paper_refPaper, save_file='example_results.csv') # results will be save in 'example_results.csv'\n",
    "df_acknowId = run_detecor(detector, df_doi_paperId, stats=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fac9978-6028-49a2-b7b1-f0f0d1d14b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PaperId</th>\n",
       "      <th>AcknowName</th>\n",
       "      <th>CommonScholarId_by_colla</th>\n",
       "      <th>CommonScholarId_by_ref</th>\n",
       "      <th>AcknowId</th>\n",
       "      <th>CollaborationApproach</th>\n",
       "      <th>CitationApproach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2145218186</td>\n",
       "      <td>Aviv Regev</td>\n",
       "      <td>1.893730e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1893730172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2105003357</td>\n",
       "      <td>Aviv Regev</td>\n",
       "      <td>1.893730e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1893730172</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2145218186</td>\n",
       "      <td>Dalit May</td>\n",
       "      <td>2.800119e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2800119218</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2145218186</td>\n",
       "      <td>Ruth Hershberg</td>\n",
       "      <td>2.155149e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2155149074</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2145218186</td>\n",
       "      <td>Yael Altuvia</td>\n",
       "      <td>2.212855e+08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>221285518</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39811</th>\n",
       "      <td>2046302208</td>\n",
       "      <td>Yves Pommier</td>\n",
       "      <td>7.199088e+08</td>\n",
       "      <td>7.199088e+08</td>\n",
       "      <td>719908761</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39843</th>\n",
       "      <td>2006465310</td>\n",
       "      <td>Frank Oliver Glöckner</td>\n",
       "      <td>1.536379e+09</td>\n",
       "      <td>1.536379e+09</td>\n",
       "      <td>1536378997</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39861</th>\n",
       "      <td>2006465310</td>\n",
       "      <td>Renzo Kottmann</td>\n",
       "      <td>2.093521e+09</td>\n",
       "      <td>2.093521e+09</td>\n",
       "      <td>2093521308</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39887</th>\n",
       "      <td>1966390421</td>\n",
       "      <td>Heidi Hofer</td>\n",
       "      <td>2.005038e+09</td>\n",
       "      <td>2.005038e+09</td>\n",
       "      <td>2005038157</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39959</th>\n",
       "      <td>1999123843</td>\n",
       "      <td>Pawel Pyk</td>\n",
       "      <td>2.065487e+08</td>\n",
       "      <td>2.065487e+08</td>\n",
       "      <td>206548729</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>907 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PaperId             AcknowName  CommonScholarId_by_colla  \\\n",
       "0      2145218186             Aviv Regev              1.893730e+09   \n",
       "6      2105003357             Aviv Regev              1.893730e+09   \n",
       "14     2145218186              Dalit May              2.800119e+09   \n",
       "17     2145218186         Ruth Hershberg              2.155149e+09   \n",
       "20     2145218186           Yael Altuvia              2.212855e+08   \n",
       "...           ...                    ...                       ...   \n",
       "39811  2046302208           Yves Pommier              7.199088e+08   \n",
       "39843  2006465310  Frank Oliver Glöckner              1.536379e+09   \n",
       "39861  2006465310         Renzo Kottmann              2.093521e+09   \n",
       "39887  1966390421            Heidi Hofer              2.005038e+09   \n",
       "39959  1999123843              Pawel Pyk              2.065487e+08   \n",
       "\n",
       "       CommonScholarId_by_ref    AcknowId  CollaborationApproach  \\\n",
       "0                         NaN  1893730172                   True   \n",
       "6                         NaN  1893730172                   True   \n",
       "14                        NaN  2800119218                   True   \n",
       "17                        NaN  2155149074                   True   \n",
       "20                        NaN   221285518                   True   \n",
       "...                       ...         ...                    ...   \n",
       "39811            7.199088e+08   719908761                   True   \n",
       "39843            1.536379e+09  1536378997                   True   \n",
       "39861            2.093521e+09  2093521308                   True   \n",
       "39887            2.005038e+09  2005038157                   True   \n",
       "39959            2.065487e+08   206548729                   True   \n",
       "\n",
       "       CitationApproach  \n",
       "0                 False  \n",
       "6                 False  \n",
       "14                False  \n",
       "17                False  \n",
       "20                False  \n",
       "...                 ...  \n",
       "39811              True  \n",
       "39843              True  \n",
       "39861              True  \n",
       "39887              True  \n",
       "39959              True  \n",
       "\n",
       "[907 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_acknowId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac693a1a-4ee0-4c17-98c8-f83e9423b1eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ee94087-e6bf-499a-9655-15acfd65fd34",
   "metadata": {},
   "source": [
    "# One by One\n",
    "It is the same as the above. But I leave the notebook records for debug."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3357d52-0a17-4e47-8fa3-bd515266af7f",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c2795e23-f00e-4c06-bc78-2e7f51e84627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Preprocessing.\n",
      "OK!! DB data(/Users/keigokusumegi/research/data/MAG/Authors/Authors.csv.hdf5) exits as vaex.\n",
      "OK!! DB data(/Users/keigokusumegi/research/data/MAG/PaperAuthorAffiliations/PaperAuthorAffiliations.csv.hdf5) exits as vaex.\n",
      "OK!! DB data(/Users/keigokusumegi/research/data/MAG/PaperReferences/PaperReferences.csv.hdf5) exits as vaex.\n"
     ]
    }
   ],
   "source": [
    "# ============ PREPROCESSING ============\n",
    "pre = Preprocessing(acknowdata_used, df_doi_paperId, FILE_DB_AUTHOR, FILE_DB_PAPER_AUTHOR, FILE_DB_PAPER_REFPAPER)\n",
    "df_acknow, v_db_author, v_db_paper_author, v_db_paper_refPaper = run_preprocess(pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1958ff-58b5-4d7b-92dc-99428df3d2b3",
   "metadata": {},
   "source": [
    "## Identify acknowledged scholars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cec75f9d-c352-4a85-821e-992f84ad312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with the necessary data\n",
    "detector = Detector(df_acknow, v_db_author, v_db_paper_author, v_db_paper_refPaper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "1e18bb50-e24e-482b-b128-696d2ee24a79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start possible scholar Id search\n",
      "End possible_acknoweldged_candidates_id (Time in this part: 11.60s)\n"
     ]
    }
   ],
   "source": [
    "# get possible acknow Ids and dataframe\n",
    "df_acknow_possibleIds_grouped, possible_acknow_ids = detector.possible_acknoweldged_candidates_id()\n",
    "\n",
    "# check\n",
    "if len(possible_acknow_ids) == 0:\n",
    "    print('Possible scholar ID containing ANY AcknowName in the input data could not be found in DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "42a891a7-8787-4bb4-88c1-7cccde9f6194",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start collaboration_approach\n",
      "    - sub step1 : _find_target_authorIds. (Time: 8.03s)\n",
      "    - sub step2: _published_paperIds_of_target_authors. (Time: 20.99s)\n",
      "      -- get all collaborators of target_authors\n",
      "      -- confine collaborators by using possible acknowledged scholars Ids(=acknow_candidate_ids) \n",
      "    - sub step3: _collaborators_of_paperId. (Time: 38.46s)\n",
      "    - sub step4: _merge_to_create_author_collabIds. (Time: 38.52s)\n",
      "  - Done: Step1.\n",
      "  - Done: Step2. (Time: 38.86s)\n",
      "  - Done: Step3. (Time: 39.14s)\n"
     ]
    }
   ],
   "source": [
    "# Collaboration approach\n",
    "df_acknow_with_collab_identified = detector.collaboration_approach(possible_acknow_ids, df_acknow_possibleIds_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "f7833c7a-0ef0-41dc-8534-b2284fd79d49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start citation_approach\n",
      "  - Done: Step1. (Time: 27.13s)\n",
      "  - Done: Step2. (Time: 27.14s)\n"
     ]
    }
   ],
   "source": [
    "# Citation approach\n",
    "df_authorIds_citedAuthorIds_identified = detector.citation_approach(df_acknow_possibleIds_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "9ccee3bf-180a-4742-be94-af1a24c5763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging collab. and citation approach results ...\n"
     ]
    }
   ],
   "source": [
    "# Combine both approaches\n",
    "df_acknowId = detector.merge_two_approach(df_acknow_with_collab_identified, df_authorIds_citedAuthorIds_identified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "467879c8-1662-4a72-8585-3edd545ea909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formating the resutls ...\n"
     ]
    }
   ],
   "source": [
    "# Formatting\n",
    "df_acknowId = detector.format_result(df_acknowId, df_doi_paperId)\n",
    "\n",
    "# save\n",
    "df_acknowId.to_csv('result', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "31c47e5c-7adc-4bda-9887-ae7232af7f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Num identified scholars by Both approach': 329,\n",
      " 'Num identified scholars by Collab. approach': 431,\n",
      " 'Num identified scholars by Reference approach': 147,\n",
      " 'Num of identified acknowledged scholars': 855,\n",
      " 'Num of input papers': 659,\n",
      " 'Num of input scholars names': 2316,\n",
      " 'Num of papers with identified acknowledged scholars': 431,\n",
      " 'Overall computational time': 1,\n",
      " 'Proportion of identified scholars per input names': '0.3692'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "pprint(detector.stats(detector.df_acknow, df_acknowId))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('3.9.4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "c5499c8d068d9fe2ff72f4cb4bdaa54f362ce8aeb64700ec8a7aa8956abb6787"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
